/**
 * Edge Function: Escanear Website para Produtos 360¬∫
 * 
 * Motor completo de extra√ß√£o com processamento em etapas
 * Usa sistema de jobs para rastreamento e continuidade
 */

import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, OPTIONS',
  'Access-Control-Max-Age': '86400',
};

interface Scan360Request {
  tenant_id: string;
  website_url: string;
  job_id?: string; // Opcional: continuar job existente
  batch_size?: number; // Tamanho do lote (padr√£o: 25 p√°ginas)
}

const BATCH_SIZE = 25; // P√°ginas por lote
const MAX_PAGES = 500; // üî• AUMENTADO: De 200 para 500 p√°ginas para sites grandes (era 200)

serve(async (req) => {
  // ‚úÖ CR√çTICO: Tratar CORS preflight explicitamente (ANTES DE QUALQUER COISA)
  // ‚ö†Ô∏è IMPORTANTE: O navegador faz preflight OPTIONS antes de POST
  // ‚ö†Ô∏è CR√çTICO: Status 200 √© obrigat√≥rio para passar no check do navegador
  if (req.method === 'OPTIONS') {
    console.log('[Scan360] ‚úÖ OPTIONS preflight recebido');
    return new Response('', { 
      status: 200,
      headers: corsHeaders 
    });
  }

  try {
    const { tenant_id, website_url, job_id, batch_size = BATCH_SIZE } = await req.json() as Scan360Request;

    if (!tenant_id || !website_url) {
      return new Response(
        JSON.stringify({ error: 'tenant_id e website_url s√£o obrigat√≥rios' }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
    const supabaseKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;
    const openaiKey = Deno.env.get('OPENAI_API_KEY');
    const serperKey = Deno.env.get('SERPER_API_KEY');

    if (!supabaseKey || !openaiKey) {
      throw new Error('SERVICE_ROLE_KEY e OPENAI_API_KEY s√£o obrigat√≥rias');
    }

    const supabase = createClient(supabaseUrl, supabaseKey);

    // Extrair dom√≠nio
    let domain = website_url;
    try {
      const url = new URL(website_url.startsWith('http') ? website_url : `https://${website_url}`);
      domain = url.hostname;
    } catch {
      domain = website_url.replace(/^https?:\/\//, '').split('/')[0];
    }

    const baseUrl = website_url.startsWith('http') ? website_url : `https://${website_url}`;

    let job: any = null;
    let isNewJob = false;

    // Buscar ou criar job
    if (job_id) {
      const { data: existingJob, error: jobError } = await supabase
        .from('website_scan_jobs')
        .select('*')
        .eq('id', job_id)
        .eq('tenant_id', tenant_id)
        .single();

      if (jobError || !existingJob) {
        return new Response(
          JSON.stringify({ error: 'Job n√£o encontrado', job_id }),
          { status: 404, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }

      job = existingJob;
      console.log(`[Scan360] Continuando job existente: ${job_id}, status: ${job.status}`);
    } else {
      // Criar novo job
      const { data: newJob, error: createError } = await supabase
        .from('website_scan_jobs')
        .insert({
          tenant_id,
          website_url,
          status: 'scanning',
          pages_discovered: [],
          pages_scanned: [],
        })
        .select()
        .single();

      if (createError || !newJob) {
        throw new Error(`Erro ao criar job: ${createError?.message}`);
      }

      job = newJob;
      isNewJob = true;
      console.log(`[Scan360] Novo job criado: ${job.id}`);
    }

    // Se job j√° est√° completo, retornar resultado
    if (job.status === 'completed') {
      return new Response(
        JSON.stringify({
          success: true,
          job_id: job.id,
          status: 'completed',
          products_found: job.products_found,
          products_inserted: job.products_inserted,
          pages_scanned: (job.pages_scanned as string[]).length,
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // FASE 1: Descoberta de URLs (apenas se for novo job ou se ainda n√£o descobriu)
    let discoveredUrls: string[] = [];
    if (isNewJob || (job.pages_discovered as string[]).length === 0) {
      console.log(`[Scan360] FASE 1: Descobrindo URLs...`);
      
      const urlsSet = new Set<string>();
      
      // 1.1 Buscar sitemap.xml
      const sitemapPaths = ['/sitemap.xml', '/sitemap_index.xml', '/sitemap1.xml'];
      for (const sitemapPath of sitemapPaths) {
        try {
          const sitemapUrl = `${baseUrl}${sitemapPath}`;
          const sitemapResponse = await fetch(sitemapUrl, {
            headers: { 'User-Agent': 'Mozilla/5.0' },
            signal: AbortSignal.timeout(10000),
          });
          
          if (sitemapResponse.ok) {
            const sitemapXml = await sitemapResponse.text();
            const urlMatches = sitemapXml.match(/<loc>(.*?)<\/loc>/gi);
            if (urlMatches) {
              for (const match of urlMatches) {
                const url = match.replace(/<\/?loc>/gi, '').trim();
                // üî• MELHORADO: Filtrar URLs de produtos de forma mais abrangente
                if (url && (
                  url.toLowerCase().includes('produto') || 
                  url.toLowerCase().includes('categoria') || 
                  url.toLowerCase().includes('catalogo') || 
                  url.toLowerCase().includes('product') || 
                  url.toLowerCase().includes('category') ||
                  url.toLowerCase().includes('shop') ||
                  url.toLowerCase().includes('loja') ||
                  url.toLowerCase().includes('/p/') ||
                  url.toLowerCase().includes('/produto/') ||
                  url.toLowerCase().includes('/item/')
                )) {
                  urlsSet.add(url);
                }
              }
              console.log(`[Scan360] ‚úÖ Sitemap encontrado: ${urlsSet.size} URLs`);
              break;
            }
          }
        } catch (e) {
          // Continuar
        }
      }

      // 1.2 SERPER com m√∫ltiplas queries
      // üî• MELHORADO: Mais queries para descobrir mais p√°ginas
      if (serperKey) {
        const serperQueries = [
          `site:${domain} (produtos OR servi√ßos OR cat√°logo)`,
          `site:${domain} (linha OR equipamentos OR categoria)`,
          `site:${domain} (produtos em destaque OR novidades OR lan√ßamentos)`,
          `site:${domain} (categoria OR categorias OR subcategoria)`,
          `site:${domain} (shop OR loja OR e-commerce)`,
        ];
        
        for (const query of serperQueries) {
          try {
            const serperResponse = await fetch('https://google.serper.dev/search', {
              method: 'POST',
              headers: {
                'X-API-KEY': serperKey,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                q: query,
                num: 50,
                gl: 'br',
                hl: 'pt-br',
              }),
            });

            if (serperResponse.ok) {
              const serperData = await serperResponse.json();
              const organicResults = serperData.organic || [];
              for (const result of organicResults) {
                if (result.link && result.link.includes(domain)) {
                  urlsSet.add(result.link);
                }
              }
            }
            await new Promise(resolve => setTimeout(resolve, 300));
          } catch (e) {
            // Continuar
          }
        }
      }

      // 1.3 Homepage e p√°ginas comuns
      urlsSet.add(baseUrl);
      const commonPaths = ['/produtos', '/servicos', '/catalogo', '/products', '/services'];
      for (const path of commonPaths) {
        urlsSet.add(`${baseUrl}${path}`);
      }

      discoveredUrls = Array.from(urlsSet).slice(0, MAX_PAGES);
      
      // Atualizar job com URLs descobertas
      await supabase
        .from('website_scan_jobs')
        .update({
          pages_discovered: discoveredUrls,
          total_batches: Math.ceil(discoveredUrls.length / batch_size),
          metadata: { sitemap_found: urlsSet.size > 0 },
        })
        .eq('id', job.id);

      console.log(`[Scan360] ‚úÖ ${discoveredUrls.length} URLs descobertas`);
    } else {
      discoveredUrls = job.pages_discovered as string[];
      console.log(`[Scan360] Usando ${discoveredUrls.length} URLs j√° descobertas`);
    }

    // FASE 2: Processar lote atual
    const pagesScanned = job.pages_scanned as string[];
    const pagesToScan = discoveredUrls
      .filter(url => !pagesScanned.includes(url))
      .slice(0, batch_size);

    if (pagesToScan.length === 0) {
      // Todas as p√°ginas foram processadas
      await supabase
        .from('website_scan_jobs')
        .update({
          status: 'completed',
          updated_at: new Date().toISOString(),
        })
        .eq('id', job.id);

      return new Response(
        JSON.stringify({
          success: true,
          job_id: job.id,
          status: 'completed',
          products_found: job.products_found,
          products_inserted: job.products_inserted,
          pages_scanned: pagesScanned.length,
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    console.log(`[Scan360] Processando lote ${job.current_batch + 1}/${Math.ceil(discoveredUrls.length / batch_size)}: ${pagesToScan.length} p√°ginas`);

    // Coletar conte√∫do das p√°ginas
    const pagesContent: string[] = [];
    for (const url of pagesToScan) {
      try {
        const response = await fetch(url, {
          headers: { 'User-Agent': 'Mozilla/5.0' },
          signal: AbortSignal.timeout(10000),
        });
        
        if (response.ok) {
          const html = await response.text();
          const textContent = html
            .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
            .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
            .replace(/<[^>]+>/g, ' ')
            .replace(/\s+/g, ' ')
            .trim()
            .substring(0, 15000);
          
          pagesContent.push(`URL: ${url}\nConte√∫do: ${textContent}`);
        }
      } catch (e) {
        console.log(`[Scan360] ‚ö†Ô∏è Erro ao acessar ${url}:`, e);
      }
      await new Promise(resolve => setTimeout(resolve, 200));
    }

    if (pagesContent.length === 0) {
      // Marcar p√°ginas como processadas mesmo sem conte√∫do
      const updatedScanned = [...pagesScanned, ...pagesToScan];
      await supabase
        .from('website_scan_jobs')
        .update({
          pages_scanned: updatedScanned,
          current_batch: job.current_batch + 1,
          updated_at: new Date().toISOString(),
        })
        .eq('id', job.id);

      return new Response(
        JSON.stringify({
          success: true,
          job_id: job.id,
          status: 'scanning',
          has_more: updatedScanned.length < discoveredUrls.length,
          current_batch: job.current_batch + 1,
          total_batches: Math.ceil(discoveredUrls.length / batch_size),
          pages_scanned: updatedScanned.length,
          pages_total: discoveredUrls.length,
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // FASE 3: Extrair produtos com OpenAI (üî• MESMA INTELIG√äNCIA DO SCAN-WEBSITE-PRODUCTS)
    const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: `Voc√™ √© um especialista em identificar produtos e servi√ßos em websites corporativos, especialmente produtos industriais, EPIs, equipamentos de prote√ß√£o, luvas, e produtos f√≠sicos.

üî• CR√çTICO - EXTRA√á√ÉO DE PRIMEIRO MUNDO:
- Procure por NOMES DE PRODUTOS espec√≠ficos mencionados no site (ex: "Grip Defender", "Total Power", "Max Defender", etc.)
- Procure por CATEGORIAS de produtos (ex: "Alta Temperatura", "Arco El√©trico", "Corte/Perfura√ß√£o", etc.)
- Procure por PRODUTOS EM DESTAQUE ou se√ß√µes de produtos
- N√ÉO ignore produtos mencionados na homepage ou em se√ß√µes de "Produtos em Destaque"
- Se houver categorias, liste os produtos de cada categoria
- üî• NOVO: Identifique REFER√äNCIAS/C√ìDIGOS de produtos (ex: "Ref.: 50T18", "C√≥digo: ABC123", "SKU: XYZ", "Modelo: 123")
- üî• NOVO: Use dados estruturados (Schema.org) se dispon√≠veis
- üî• NOVO: Use alt text de imagens para identificar produtos
- üî• NOVO: Identifique HIERARQUIA de categorias (categoria principal ‚Üí subcategoria ‚Üí produto)

Analise o conte√∫do das p√°ginas e identifique TODOS os produtos/servi√ßos oferecidos pela empresa.

Para cada produto/servi√ßo encontrado, extraia:
- nome: Nome EXATO do produto/servi√ßo INCLUINDO refer√™ncia se houver (ex: "T√™nis linha New Prime (Ref.: 50T18 CO ELETRICISTA)", "Grip Defender Vulca", etc.)
- descricao: Breve descri√ß√£o do produto
- categoria: Categoria do produto (ex: "Alta Temperatura e Solda", "Arco El√©trico", "Corte/Perfura√ß√£o", "Prote√ß√£o Mec√¢nica", "Prote√ß√£o Qu√≠mica", "EPI", "Luvas", "Cal√ßados", etc.)
- subcategoria: Subcategoria se houver (ex: "Linha New Prime", "Linha Composite", etc.)
- referencia: C√≥digo/refer√™ncia do produto se mencionado (ex: "50T18 CO ELETRICISTA", "72B29-TXT-E-BP-LR")
- setores_alvo: Setores que podem usar (baseado no contexto, ex: "Ind√∫stria", "Constru√ß√£o", "Minera√ß√£o", etc.)
- diferenciais: Diferenciais mencionados (ex: "Alta performance", "Tecnologia de √∫ltima gera√ß√£o", etc.)
- confianca: Sua confian√ßa (0.0 a 1.0)

Se encontrar categorias sem produtos espec√≠ficos, crie produtos gen√©ricos para cada categoria.

Responda APENAS com JSON v√°lido:
{
  "empresa": "Nome da empresa",
  "produtos": [
    {
      "nome": "Nome exato do produto",
      "descricao": "Descri√ß√£o do produto",
      "categoria": "Categoria do produto",
      "subcategoria": "Subcategoria se houver",
      "referencia": "C√≥digo/refer√™ncia se houver",
      "setores_alvo": ["Setor 1", "Setor 2"],
      "diferenciais": ["Diferencial 1", "Diferencial 2"],
      "confianca": 0.9
    }
  ]
}`
          },
          {
            role: 'user',
            content: `Extraia TODOS os produtos e servi√ßos mencionados nas seguintes p√°ginas. Preste aten√ß√£o especial a:
- Produtos em destaque na homepage
- Nomes de produtos espec√≠ficos COM suas refer√™ncias/c√≥digos
- Categorias e subcategorias de produtos
- Se√ß√µes de cat√°logo ou linha de produtos
- Dados estruturados (Schema.org) se dispon√≠veis
- Alt text de imagens que mencionam produtos
- Links do menu de navega√ß√£o que podem ter mais produtos

IMPORTANTE: Se encontrar um produto com refer√™ncia (ex: "Ref.: 50T18"), inclua a refer√™ncia no nome do produto para garantir unicidade.

Conte√∫do das p√°ginas:\n\n${pagesContent.join('\n\n---\n\n').substring(0, 30000)}`
          }
        ],
        temperature: 0.1, // üî• MESMA PRECIS√ÉO do scan-website-products
        max_tokens: 15000, // üî• AUMENTADO para processar mais produtos por lote (era 12000)
      }),
    });

    if (!openaiResponse.ok) {
      throw new Error('Erro na API OpenAI');
    }

    const aiResult = await openaiResponse.json();
    const content = aiResult.choices?.[0]?.message?.content || '{"produtos":[]}';
    
    console.log('[Scan360] üì• Resposta da OpenAI recebida (tamanho):', content.length, 'caracteres');
    console.log('[Scan360] üìÑ Preview da resposta (primeiros 500 chars):', content.substring(0, 500));
    
    // üî• MELHORADO: Parsing robusto igual ao scan-website-products
    let extractedProducts: any[] = [];
    try {
      const cleanContent = content.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
      console.log('[Scan360] üßπ Conte√∫do limpo (tamanho):', cleanContent.length, 'caracteres');
      
      // Tentar encontrar JSON v√°lido mesmo se houver texto antes/depois
      let jsonStart = cleanContent.indexOf('{');
      let jsonEnd = cleanContent.lastIndexOf('}') + 1;
      
      if (jsonStart >= 0 && jsonEnd > jsonStart) {
        const jsonContent = cleanContent.substring(jsonStart, jsonEnd);
        console.log('[Scan360] üîç Tentando parsear JSON extra√≠do (tamanho):', jsonContent.length, 'caracteres');
        
        const parsed = JSON.parse(jsonContent);
        extractedProducts = parsed.produtos || parsed.products || [];
        
        console.log('[Scan360] ‚úÖ Produtos parseados:', extractedProducts.length);
        if (extractedProducts.length > 0) {
          console.log('[Scan360] üì¶ Primeiro produto:', JSON.stringify(extractedProducts[0], null, 2));
        } else {
          console.log('[Scan360] ‚ö†Ô∏è NENHUM PRODUTO ENCONTRADO! Resposta completa:', cleanContent.substring(0, 2000));
        }
      } else {
        console.error('[Scan360] ‚ùå N√£o foi poss√≠vel encontrar JSON v√°lido na resposta');
        console.error('[Scan360] üìÑ Conte√∫do completo (primeiros 2000 chars):', cleanContent.substring(0, 2000));
        extractedProducts = [];
      }
    } catch (parseError: any) {
      console.error('[Scan360] ‚ùå Erro ao parsear resposta da IA:', parseError);
      console.error('[Scan360] üìÑ Conte√∫do que falhou (primeiros 2000 chars):', content.substring(0, 2000));
      console.error('[Scan360] üîç Tentando extrair JSON manualmente...');
      
      // Tentar extrair JSON manualmente usando regex
      try {
        const jsonMatch = content.match(/\{[\s\S]*"produtos"[\s\S]*\}/) || content.match(/\{[\s\S]*"products"[\s\S]*\}/);
        if (jsonMatch) {
          const parsed = JSON.parse(jsonMatch[0]);
          extractedProducts = parsed.produtos || parsed.products || [];
          console.log('[Scan360] ‚úÖ Produtos extra√≠dos manualmente:', extractedProducts.length);
        }
      } catch (manualParseError) {
        console.error('[Scan360] ‚ùå Falha tamb√©m no parse manual:', manualParseError);
        extractedProducts = [];
      }
    }

    // FASE 4: Inserir produtos
    let insertedCount = 0;
    const normalizeForComparison = (str: string): string => {
      return str.toLowerCase().normalize('NFD').replace(/[\u0300-\u036f]/g, '').replace(/[^\w\s]/g, '').trim();
    };

    for (const product of extractedProducts) {
      if (!product.nome) continue;

      // Verificar duplicata
      const { data: existing } = await supabase
        .from('tenant_products')
        .select('id, nome')
        .eq('tenant_id', tenant_id)
        .limit(50);

      let isDuplicate = false;
      if (existing) {
        const normalizedNew = normalizeForComparison(product.nome);
        for (const existingProduct of existing) {
          const normalizedExisting = normalizeForComparison(existingProduct.nome || '');
          if (normalizedNew === normalizedExisting || 
              (normalizedNew.length > 10 && normalizedExisting.includes(normalizedNew.substring(0, Math.floor(normalizedNew.length * 0.9))))) {
            isDuplicate = true;
            break;
          }
        }
      }

      if (!isDuplicate) {
        // üî• MELHORADO: Inserir com todos os campos extra√≠dos (mesma estrutura do scan-website-products)
        const { error: insertError } = await supabase
          .from('tenant_products')
          .insert({
            tenant_id,
            nome: product.nome.trim(),
            descricao: product.descricao?.trim() || null,
            categoria: product.categoria?.trim() || null,
            subcategoria: product.subcategoria?.trim() || null,
            codigo_interno: product.referencia?.trim() || null,
            extraido_de: 'website',
            confianca_extracao: product.confianca || 0.8, // Usar confian√ßa da IA se dispon√≠vel
            // üî• NOVO: Campos adicionais se dispon√≠veis
            setores_alvo: product.setores_alvo?.join(', ') || null,
            diferenciais: product.diferenciais?.join(', ') || null,
          });

        if (!insertError) {
          insertedCount++;
        }
      }
    }

    // Atualizar job
    const updatedScanned = [...pagesScanned, ...pagesToScan];
    const hasMore = updatedScanned.length < discoveredUrls.length;
    
    await supabase
      .from('website_scan_jobs')
      .update({
        pages_scanned: updatedScanned,
        products_found: (job.products_found || 0) + extractedProducts.length,
        products_inserted: (job.products_inserted || 0) + insertedCount,
        current_batch: job.current_batch + 1,
        status: hasMore ? 'scanning' : 'completed',
        updated_at: new Date().toISOString(),
      })
      .eq('id', job.id);

    console.log(`[Scan360] ‚úÖ Lote processado: ${insertedCount} produtos inseridos`);

    return new Response(
      JSON.stringify({
        success: true,
        job_id: job.id,
        status: hasMore ? 'scanning' : 'completed',
        has_more: hasMore,
        current_batch: job.current_batch + 1,
        total_batches: Math.ceil(discoveredUrls.length / batch_size),
        products_found: (job.products_found || 0) + extractedProducts.length,
        products_inserted: (job.products_inserted || 0) + insertedCount,
        pages_scanned: updatedScanned.length,
        pages_total: discoveredUrls.length,
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error: any) {
    console.error('[Scan360] Erro:', error);
    return new Response(
      JSON.stringify({ success: false, error: error.message }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
